---
layout: post
title: "운영체제1"
comments: true
category: U-operating-system
---

> 4.10 최종수정, 개념 추가, 예제 추가 (예제 답은 아직 불확실함)


## 운영체제

하드웨어를 관리하고 어플리케이션 프로그램들이 실행되는 환경을 제공해주는 소프트웨어  리소스를 할당하고, 프로그램을 컨트롤한다.

### 부트스트랩 프로그램 (=부트스트랩 로더 =펌웨어)

ROM 또는 EEPROM에 저장되어 운영체제를 불러온다.

### 인터럽트

운영체제는 인터럽트에 의해 움직인다(interrupt-driven)

소프트웨어가 발생시킨 인터럽트 = 시스템 콜 = 트랩(trap)

### 소프트웨어 실행 사이클

1. 프로그램 로드
2. 명령어 페치(Fetch, 읽기)
3. 명령어 디코딩(해석)
4. 오퍼랜드 페치
5. 명령어 실행
6. 결과 저장
7. (2로 돌아가 반복)

### 저장공간

>**(비용▲ 속도▲ volatile)**
>
>레지스터
>
>캐시 (메인 메모리의 내용을 복사하여 빠르게 접근할 때 사용)
>
>메인 메모리
>
>전기 디스크
>
>자기 디스크
>
>옵티컬 디스크
>
>자기 테이프
>
>**(비용▼ 속도▼ non-volatile)**

### I/O 구조?

각각의 I/O 디바이스는 로컬 버퍼를 가진다.

보통 I/O 디바이스 드라이버에서 인터럽트를 발생시켜 CPU와 I/O 디바이스 사이에서 데이터 이동이 일어난다.

### DMA (Direct Memory Access)

CPU를 거치는 인터럽트가 너무 많이 발생할 경우 오버헤드가 커진다.

그래서 I/O 장치에서 CPU를 거치지 않고 바로 블록 단위로 입출력하는 인터럽트를 발생시킨다.

### 오버헤드

낭비되는 메모리나 속도 등을 의미한다.

### 커널 모드

커널 실행 모드

### 유저 모드

유저 실행 모드

 * 타이머의 값 설정 - 커널 모드
 * 시계 읽기 - 유저 모드
 * 인터럽트 종료 - 커널 모드
 * I/O 디바이스 접근 - 커널 모드
 * trap 명령어 발동 - 유저 모드

## 운영체제의 역할

### 프로세스 관리

 * 프로세스와 스레드의 스케쥴링 (cpu)
 * 유저와 시스템의 프로세스를 만들어나 제거
 * 프로세스를 중단하거나 재개하는 역할
 * 프로세스 synchronization과 프로세스 communication을 위한 매커니즘을 배포

### 메모리 관리

 * 메모리 상의 다음 실행될 명령어들 전부
 * 메모리 상의 모든 데이터
 * cpu를 최적화하기 위해 메모리에 상주한 여러 프로그램들
 * 메모리 추적 관리
 * 어느 프로세스의 메모리를 할당하고 해제할 것인지 결정
 * 메모리 할당과 해제

### 저장공간 관리

 * 파일 시스템 관리
 * 복잡한 저장공간 관리
 * 캐싱
 * I/O 서브시스템

### 보호와 보안

 * 보호: 유저id 그룹id
 * 보안: password

### 운영체제 서비스

 * 유저 인터페이스(User Interface)
 * 프로그램 실행(Program execution)
 * I/O 동작(I/O operations)
 * 파일 시스템 관리(File-system manipulation)
 * 커뮤니케이션(Communication)
 * 에러 디텍션(Error detection)
 * 리소스 할당(Resource allocation)
 * 어카운팅(Accounting) - 자원 관리
 * 보호 & 보안 (Protection(local) and security(worldwide))

## 시스템 콜

###시스템 콜 종류

프로세스 컨트롤, 파일 관리, 디바이스 관리, 정보 유지보수, 커뮤니케이션, 보호(Protection)를 담당한다.

### 시스템 콜 파라미터 전달

 a) 레지스터에 넣어 전달
 b) 메모리상의 블록에 전달하고 레지스터로 주소 전달
 c) 스택에 저장하고, 운영체제에서 POP

### 시스템 콜 정의 과정

a. 함수 정의

```c
asmlinkage long sys_helloworld(void){
printk("Hello, World !!!\n");
}

```

b. 번호 할당

```c
#define __NR_helloworld 223

```

c. 함수 등록

```c
ENTRY(sys_call_table)
	.long sys_~~~~~~
    .long sys_~~~~~~
    .long sys_helloworld

```

d. 커널 리빌드, 테스트 (syscall 호출)

```c
_syscall0(int, helloworld);
int main(void)
{
	helloworld();
}

```

## 운영체제 구조

### Monolithic 구조

![sch_monolithic](/images/sch_monolithic.PNG "monolithic")

운영체제 등 소프트웨어의 레벨이 구체적으로 정의되지 않음

MS-DOS, 전통적인 UNIX 시스템

구조를 파악하는데 어려움이 있음

### Layered approach

![sch_layered](/images/sch_layered.PNG "layered")

붙어있는 껍질끼리만 데이터 전송이 가능

디버깅이 편리하고 구조 파악이 쉽다.
 
다양한 구조를 표현하는데 한계가 있고, 오버헤드가 많이 발생

### Microkernels

커널의 영역을 최대한 축소

메세지 패싱 방식을 이용해서 유저 모듈끼리 통신한다.

OS의 확장이 용이하고, 보안성과 신뢰성을 가졌다. (대부분의 프로그램이 유저 모드에서 실행되므로)

시스템 함수 오버헤드(메세지 패싱 오버헤드)가 발생

### Modules

OS - 다수의 모듈 - 유저 어플리케이션 구조

모듈끼리 메세지 패싱이 필요없고, 서로 인터페이스를 통해 통신이 가능하다.

### Hybrid

IOS, 안드로이드 등등..

# 프로세스

### 프로세스 구조

 * TEXT
 * 프로그램 카운터
 * STACK
 * DATA
 * HEAP

### I/O-bound 프로세스

I/O 작업 위주

### CPU-bound 프로세스

CPU 연산 작업 위주

### 프로세스 작업 주기

![sch_process-routine](/images/sch_process-routine.PNG "process-routine")

 * 새로 만들어진 상태 - New
 * 실행 중 상태 - Running
 * 기다리는 중 상태 (I/O 작업의 완료나 signal을 받을 때까지) - Waiting
 * 프로세서에 등록되기까지 준비중인 상태 - Ready
 * 종료 상태 - Terminated
 
추가적으로 알아두면 좋은 것, Terminated와 halted, aborted는 미묘하게 다르다.

Terminated는 정상적으로 종료된 상태, halted는 오류 등으로 중단된 상태, aborted는 halted와 비슷하게 갑작스럽거나 오류로 인한 중지.

### 프로세스 컨트롤 블럭(PCB:Process Control Block = task control block)

저장되는 정보

 * 프로세스 상태
 * 프로그램 카운터
 * CPU 레지스터
 * CPU 스케쥴링 정보
 * 메모리 관리 정보
 * 어카운팅 정보 (CPU와 시간 사용량, 시간 제한, account id, process id 등)
 * I/O 상태 정보
 * (스레드가 존재할 때) 각각의 스레드 정보
 
컨텍스트 스위치(Context Switch)가 일어날 때 실행되고 있는 프로세스의 PCB에 현재의 컨텍스트(context)를 저장하고, 다음 실행할 프로세스의 PCB의 컨텍스트를 가져온다. (컨텍스트: PCB에 저장된 정보들)

## 프로세스 스케쥴링 큐

### Job 큐

모든 프로세스가 담겨 있다.

### 레디 큐

작업을 위해 기다리는 중인 프로세스가 담겨 있다.

메인 메모리의 모든 프로세스가 링크드 리스트 형태로 담겨 있다.

레디 큐 헤더는 리스트의 첫 PCB와 끝 PCB의 포인터를 가지고 있으며, 각각의 PCB는 다음 PCB를 가리키는 포인터를 가진다.

### 디바이스 큐

//이미지 queing diagram 필요

특정 I/O 작업을 위해 기다리는 중인 프로세스가 담겨 있다.

I/O 작업 예:

 * I/O request -> I/O queue
 * time slice expired (queue)
 * fork a child -> fork queue
 * wait for an interrupt -> interrupt queue

## 스케쥴러

### long-term 스케쥴러 (Job 스케쥴러)

어떤 프로세스가 mass-storage device(저장장치)에 spool된 pool에서 레디 큐로 들어와야 하는지 선택한다.

멀티프로그래밍의 수준을 결정한다. OS의 리소스 할당(특히 메모리) 정책에 영향을 많이 받는다.

### short-term 스케쥴러 (CPU 스케쥴러)

어떤 프로세스가 실행되고 메모리를 할당받아야 하는지 선택한다.

### mid-term 스케쥴러

어떤 프로세스가 스와핑(Swapped out/in) 되어야 하는지 선택한다.

### 컨텍스트 스위치

프로세스끼리 실행상태를 바꾸는 것

## 프로세스의 동작

### 프로세스 생성

pid - 프로세스 고유 id

부모 프로세스 - 루트 프로세스

자식 프로세스 - 부모로부터 파생된 프로세스

### 리소스 공유 모드

 a) 부모와 자식 프로세스가 모든 리소스 공유
 
 b) 자식이 부모의 일정 부분을 공유 (일부는 OS로부터 받음)
 
 c) 공유하지 않음 (OS로부터 받음)

### 실행 모드

 a) 부모와 자식이 동시에 실행중인 상태
 
 b) 부모가 자식이 실행중인 동안 중지

### 주소공간 모드

 a) 자식이 부모의 복사본
 
 b) 자식이 그 주소에 새롭게 로드된 프로그램

### 유닉스

 * 부모: fork() -> (child process 생성) -> wait -> (child process 종료) -> resumes
 * 자식: exec() -> exit()

```c
int main()
{
	pid_t pid;
    /*fork another process */

    pid = fork();
    if(pid<0){
    fprintf(stderr, "Fork error ...\n");
    exir(-1);
    }
    else if(pid == 0){ /* child process */
    execlp("/bin/ls", "ls", NULL);
    }
    else {  /*parent process */
    	/*parent process will wait for the child process to complete */
        wait(NULL);
        printf("Child Completed ...\n");
        exit(0);
    }
}

```

## 프로세스 종료

 * 시스템에게 exit 호출해서 지워달라고 요청하면 시스템이 지워줌
 * abort를 이용하면 부모 프로세스에서 자식 프로세스를 종료할 수 있다.
  * 자식이 리소스 용량 초과하면
  * 자식에게 할당된 일이 더이상 필요하지 않음
  * 부모가 종료될 때 운영체제가 고아 프로세스를 허용하지 않는다면
  
프로세스가 종료되면 운영체제에 의해 해당 리소스가 할당 해제된다.

그러나 프로세스 테이블에는 프로세스의 종료 상태가 포함되어 있으므로 프로세스 테이블의 항목은 부모 호출이 대기()될 때까지 그대로 유지되어야 한다. 

종료되었지만 부모가 아직 wait()를 부르지 않은 프로세스는 좀비 프로세스로 알려져 있다.

UNIX나 LINUX에서는 주기석으로 init 프로세스가 wait()을 호출해서 고아 프로세스를 제거해준다.

//이해가 좀 더 필요

### Cascaded termination

부모가 종료될때 부모의 프로세스 트리 모두 종료

## IPC: Interprocess Communication

independent 프로세스: 독립적

cooperating 프로세스: 다른 프로세스에 영향을 줌

 * 목적: 정보 공유, 계산속도 향상, 모듈화, 편리성

## IPC 모델

<!-- 사진 필요 -->

### 공유 메모리(Shared memory)

Cache coherency 문제 (shared data가 여러 캐시를 통해 전달되기 때문에 생김)

공유 메모리 영역은 OS가 관여하지 않는다.

Synchronization(동기화) 문제 발생 - 동시에 같은곳에 쓰기를 하고 있지 않다고 가정해야 한다.
 * unbounded buffer 방식 해결법: consumer는 new item이 생길 때까지 기다려야되고, producer는 항상 공급 가능
 * bounded buffer 방식 해결법: consumer는 버퍼가 비어있으면 wait 상태, producer는 버퍼가 가득 차 있으면 wait 상태가 된다.

### 메세지 패싱(Message Passing)

커뮤니케이션 링크를 통한 메세지 교환 (send와 receive 함수 이용)

>메세지 패싱 구현의 방법론
>
>링크가 어떻게 설정되는가
>
>링크가 두 개 이상의 프로세스에 의해 연결될 수 있나
>
>모든 각각의 communicating 프로세스에 대해 얼마나 많은 링크가 존재하는가
>
>링크의 capacity란
>
>링크가 처리할 수 있는 메세지의 크기는 고정되어있는가
>
>링크가 단방향인가 쌍방향인가
>

### 직접 커뮤니케이션 방식(Direct Communication)

 * 프로세스가 서로를 뚜렷하게 이름을 붙여주어야 한다.
 * 링크의 속성
  * 자동 연결
  * 한 쌍의 communicating 프로세스에 대해서만 연결
  * 한 쌍의 프로세스는 한 개의 링크
  * 단방향 방식일수도, 쌍방향일수도 있음

대칭(Symmetry) 방식

 * send(P, message) - 프로세스 P에게 message를 보낸다
 * receive(Q, message) - 프로세스 Q로부터 message를 받는다

비대칭(Asymmetry) 방식

 * sent(P, message)
 * receive(id, message) - 아무곳에서나 메세지를 받음
  * id가 상황마다 communication을 필요로 하는 프로세스의 이름으로 정해진다

**컴파일 시간에 이름을 알 수 없고, 상대방의 이름이 달라지면 문제가 생긴다**

**두 방식의 공통적인 단점은 결과 프로세스 정의의 제한적 모듈성이다. 엥??**

 * 한 프로세스의 id를 변경하는데 다른 모든 프로세스의 정의를 찾아봐야 되는 단점이 있다.

### 간접 커뮤니케이션 방식(Indirect Communication)

 * 굳이 이름을 붙여주지 않아도 메세지가 메일박스 (포트)를 통해 전달됨
 * 각각의 메일박스는 고유id가 있음
 * 메일박스를 공유할 때만 링크가 설정되어 서로 communicating 가능
 * 링크가 많은 프로세스끼리 연결 가능
 * 각 쌍의 프로세스는 여러 communication 링크를 가질 수 있다
 * 단방향일수도, 쌍방향일수도 있음
 * 작동방식
  * 메일박스를 만든다
  * 메세지를 주고받는다
  * send(M, message) : 메일박스 M에 메세지를 보냄
  * receive(M, message) : 메일박스 M으로부터 메세지를 받음
  * 만약 동시에 받게될 경우는 전부 받을지, 하나만 받을지, 보내는사람이 선택하도록 알려줄지 구현 가능
  * 메일박스를 제거한다 (제거할 경우 사용중인 프로세스들에게 알려주어야 한다.)

**하나의 메일에 동시에 두 개 이상의 프로세스가 접근할 경우 동기화(synchronization) 문제 해결책들**

a) 하나의 링크에 최대 두 개의 프로세스를 묶도록 함

b) 한순간에 최대 하나의 프로세스만 receive() 가 가능하도록 함

c) 시스템이 어느 프로세스가 메세지를 수신할지 결정함

d) 송신자에게 수신자를 결정하게 함

OS의 mailbox는 독립적이여서 프로세스에 붙을 수 없으므로, 프로세스가 mailbox를 생성, 삭제할 수 있도록 허용해야 한다.

### 동기화 방식(Synchronization)

메세지 패싱은 blocking 방식이거나 non-blocking 방식 둘 중 하나이다.

Blocking: Synchronous 동기식

 * 보내는 이(sender): 보낸 메세지를 받을 때까지 sender가 waiting 상태여야 한다.
 * 받는 이(receipient): 메세지가 올 때까지 얌전히 waiting 상태여야 한다.

non-blocking: Asynchronous 비동기식
 * 보내는 이(sender): 메세지를 보낸 이후에도 쭉 running 상태에 머물러 있다.
 * 받는 이(receipient): 메세지를 받지 못하면 NULL, 받으면 받은 메세지를 리턴해주기 때문에 waiting 할 필요가 없다.

Blocking과 non-blocking 방식으로 각각 sender와 receipient를 구현할 수 있는데 이것들을 조합해서 새롭게 쓸 수도 있다.

+ 추가상식: 여기서 sender와 receipient를 모두 blocking 방식으로 구현하면 Rendezvous 랑데뷰 라고 부른다.

### 버퍼링 방식(Buffering)

버퍼 = 링크에 붙은 메세지의 큐

capacity, 즉 수용할 수 있는 공간에 따라 방식이 나뉜다.

a) Zero capacity(=message system with no buffering)

큐의 크기가 0이여서 메세지가 보관이 안된다. 그러므로 Rendezvous 랑데뷰 방식으로 구현해야 한다. (sender, recipient 모두 blocking)

b) bounded capacity(=automatic buffering의 일종)

큐의 크기가 n이고, 큐가 비거나 꽉찬 상태가 아니라면 새로운 메세지가 큐에 들어오며, recipient가 바로 가져갈 수 있다.

 * 큐가 whole-free(빈 상태)일 경우 - recipient는 메세지가 올 때까지 blocking 상태여야 된다.
 * 큐가 full(가득 찬 상태)일 경우 - sender는 메세지가 빌 때까지 blocking 상태여야 된다.

c) unbounded capacity(=automatic buffering의 일종)

큐의 크기가 무한~~~ 큐 안에 있는 메세지들이 빠져나가지 않아도 되어 sender는 항상 non-blocking 상태

## 클라이언트-서버 간의 통신

### 소켓

communication의 엔드포인트

소켓은 포트 번호와 연결된 IP 주소로 식별된다.

### 리모트 프로시져 콜 (Remote Procedure call)

별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게하는 프로세스 간 통신 기술이다.

다시 말해, 원격 프로시저 호출을 이용하면 프로그래머는 함수가 실행 프로그램에 로컬 위치에 있든 원격 위치에 있든 동일한 코드를 이용할 수 있다.

IPC와 달리 RPC는 deamon에 의해서 관리되어진다.

* Stub
 * 클라이언트-사이드 프록시
 * ... (자세히 안해도됨)

## 파이프

### 파이프 구현의 문제

 * 방향성
  * 크게 단방향(방향성이 있음)과 쌍방향(방향성이 없음)으로 나누어진다.
 * 데이터 전송 방식
  * half duplex: 한 번에 send나 recieve중 하나만 할 수 있다.
  * full duplex: send를 하면서 recieve 도 가능하다.
 * 관계에 따라
  * (parent-child)와 같은 관계가 커뮤니케이션하는 프로세스간에 존재해야 하는가?
 * 네트워크에 따라
  * 글로벌 네트워크에서의 파이프와 로컬 네트워크 안의 파이프로 나누어진다.

### ordinary (anonymous) 파이프

* 두 프로세스끼리만 통신하도록 하는 파이프
* 쌍방향(방향성이 없다)
* 프로세스간 통신이 끝나면 파이프가 닫힌다
* 파이프를 만든 프로세스 바깥에서는 접근 불가
* 보통 부모가 자식과 통신할때 쓴다

### named 파이프

* 여러 프로세스가 커뮤니케이팅에 사용 가능하다
* 쌍방향(방향성이 없다)
* 프로세스간 통신이 끝나도 계속 존재
* 부모-자식간 관계 필요없음

### 파이프와 메세지 패싱의 차이점

파이프: bit 단위로 스트림을 보낸다 (비트스트림)

메세지 패싱: 메세지를 구조화해서 보낸다. (Structured Message)

### Get/Set Priority

### Get ID

### Get PCB

## 쓰레드

 * CPU 효율의 기본 단위
 * 쓰레드 ID, 프로그램 카운터, 레지스터 세트, 스택으로 구성되어 있다.
 * 같은 프로세스의 다른 쓰레드와 자원을 공유

### 쓰레드의 장점

 * 반응성
 * 자원 공유 (구현의 용이성 측면)
 * 경제적 (메모리 할당 측면)
 * 확장성(Scalability, 멀티 cpu에서 멀티 쓰레딩 가능)

```c
#include <pthread.h>
#include <stdio.h>

int sum; /* this data is shared by the threads */
void *runner(void *param);

int main(int argc, char *argv[])
{
    pthread_t tid;
    pthread_attr_t attr;

    pthread_attr_init(&attr);	/* get the default attributes */
    pthread_create(&tid, &attr, runer, argv[1]);	/* create a thread */
    pthread_join(tid, NULL);	/* wait for the thread to exit */

    printf("SUM = %d\n", SUM);
}

/* The thread will begin control in this function */
void *runner(void * param)
{
    int i, upper = atoi(param);
    sum = 0;

    for(i =1; i <= upper; ++i)
        sum += 1;

    pthread_exit(0);
}

```

# 멀티코어 프로그래밍

싱글코어 프로그램에서 쓰레드 실행

 * T1 - T2 - T3 - T4 - T1 - T2 - T3 - T4 - ...

멀티코어 프로그램에서 쓰레드 실행

 * T1 - T3 - T1 - T3 - ...
 * T2 - T4 - T2 - T4 - ...

### 유저 쓰레드

 * 유저 레벨 쓰레드 라이브러리에 의해 관리
 * ex ) POSIX Pthread, Win32 thread, Java thread

### 커널 쓰레드

 * 운영체제에 의해 관리
 * ex ) Windows XP/2000, Solaris, Linux, Mac OS X

## 멀티쓰레딩 모델

### Many-to-One 모델

많은 유저 레벨 쓰레드가 하나의 커널 쓰레드로 매핑

유저 쓰레드에 의해 관리됨

만약 쓰레드가 blocking 시스템 콜을 호출 시 모든 프로세스가 block됨

### One-to-One 모델

각각의 유저 레벨 쓰레드가 각각의 커널 쓰레드로 매핑

오버헤드가 매우 커짐

### Many-to-Many 모델

많은 유저 레벨 쓰레드가 적거나 같은  수의 커널 쓰레드로 매핑

### Two-level 모델

Many-to-Many + One-to-One

## 쓰레드 라이브러리

구현 방법

 * 유저 스페이스에 라이브러리 전부 구현
 * 커널 레벨 라이브러리가 운영체제에 의해 지원

### Pthread

 * 쓰레드 생성과 씽크로를 `POSIX standard (IEEE 1003.1c)` 로 구현
 * API가 쓰레드 라이브러리의 동작을 정함 (라이브러리에 달려있음)
 * 유저레벨이나 커널레벨

### Java Thread

 * JVM에 의해 관리
 * 운영체제에 의해 지원되는 전형적인 쓰레드 모델

### 쓰레딩 구현 문제

> fork() exec 시스템 콜의 의미 정의
>
> 타겟 쓰레드의 쓰레드 종료 (Asynchronous or deferred)
>
> 시그널 핸들링
>
> 쓰레드 풀
>
> 쓰레드-특정 데이터
>
> 스케쥴러 행위 (Many-to-Many, Two-level model 등등 모델의 선택)


# 스케쥴링

멀티프로그래밍을 통해 CPU를 최적화 가능

실행할 준비가 된 프로세스들에 CPU를 할당해 줌

### 멀티프로그래밍

한개 프로세스 안의 CPU 연산 작업과 I/O 작업은 동시에 이루어질 수 없기 때문에 둘을 적절히 분배하여 CPU가 쉬지 않게 한다.

### 타임쉐어링 (멀티태스킹)

멀티프로그래밍을 여러 개의 프로세스에 적용시킨 것으로, 여러 개의 프로세스가 돌아가면서 CPU를 할당받는다.

### Job 스케쥴링

프로세스가 메모리에 불러질때

### CPU 스케쥴러 (=short-term scheduler)

ready 상태의 프로세스를 ready-queue 에서 꺼내 CPU 자원을 할당해준다.

### CPU 스케쥴링

프로세스가 실행될 때

### Swapping

프로세스의 실행 상태를 바꿈

### 가상메모리

메모리가 부족할 때

![sch_process-routine](/images/sch_process-routine.PNG "process-routine")

다음의 경우 스케쥴링이 필요

1. running -> waiting (I/O request나 child 프로세스가 끝나기를 기다리는 (wait()) 부모)
2. running -> ready (interrupt 발생)
3. waiting -> ready (I/O completion)
4. Terminates

1, 4번에 기반하여 스케쥴링을 구현: nonpreemptive

2, 3번에 기반하여 스케쥴링을 구현: preemptive (coorperative)

### nonpreemptive(=cooperative)

프로세스에 작업이 할당되면 끝날때까지 다른 프로세스로 넘어가지 않음

### preemptive

프로세스에 작업이 할당되어도 스케쥴러에 의해 다른 프로세스로 넘어감 (타이머가 필요하다.)

Data sharing을 사용할 경우 다른 프로세스가 preempted되어 공유 자원을 I/O 하게 되면 synchronization 문제(데이터 불일치)가 발생한다.

이를 시스템 콜(system call)이 I/O 작업을 끝낼 때까지 프로세스의 제어권을 유지하도록 하여 해결 가능하지만, 이는 오버헤드가 너무 커진다.

+ 인터럽트에 영향을 받는 코드는 동시에 사용되지 않도록 보장되어야 한다. 이러한 코드들은 그래서 진입 시 인터럽트를 비활성화하고 종료 시 인터럽트를 다시 활성화한다. 인터럽트를 비활성화하는 코드 섹션은 자주 발생하지 않으며 일반적으로 지침이 거의 포함되어 있지 않다.

## 디스패쳐(Dispatcher)

short-term scheduler에게 선택된 프로세스에게 CPU 제어권을 주는 모듈.

cpu 제어권들

 * 콘텍스트 스위치
 * 유저 모드로 스위치
 * 프로그램 재시작을 위해 프로그램의 적당한 위치로 점프

### 디스패치 지연 시간(Dispatch latency)

어떤 프로세스를 종료하고 다른 프로세스가 시작될때까지의 딜레이 시간

## 스케쥴링 Criteria

### CPU 최적화

항상 CPU를 바쁘게 만든다.

이론적으로 CPU의 0~100%를 사용하며, 실제로는 40~90%를 항상 사용하게 된다.

### Throughput

한 타임 유닛(Time Unit)에 실행이 완료되는 프로세스의 갯수

### Turnaround time

한 프로세스가 온전하게 실행이 완료될때까지 걸리는 시간(메모리에 들어가기 위해 기다리는 시간 + ready queue에서 기다리는 시간 + CPU 실행하는 시간 + I/O하는 시간)

### Waiting time

프로세스가 arrive 한 후 ready-queue에서 기다린 총 시간

### Response time

요청이 전달되고 첫 응답이 생산되기까지 걸리는 시간 (멀티태스킹 환경)

interactive 시스템에서, turnaround time은 최고의 스케쥴링 criteria가 아닐 수 있다.

종종 프로세스는 일부 출력을 상당히 일찍 생성할 수 있으며 이전 결과가 사용자에게 출력되는 동안 새로운 결과 계산을 계속할 수 있다.

interactive 시스템에서, 평균 응답 시간을 최소화하는 것보다 응답 시간의 차이를 최소화하는 것이 더 중요하다

## 스케줄링 알고리즘

### FCFS (First-Come, First-Served) 스케쥴링

![sch_FCFS](/images/sch_FCFS.JPG "FCFS")

nonpreemptive 방식으로 동작한다.

프로세스의 Waiting time

 * p1 = 0
 * p2 = 24
 * p3 = 27

평균 Waiting time = (0 + 24 + 27) / 3 = 17

![sch_FCFS2](/images/sch_FCFS2.JPG "FCFS")

도착하는 순서가 바뀌었으므로

프로세스의 Waiting time

 * p1 = 6
 * p2 = 0
 * p3 = 3

평균 Waiting time = (6 + 0 + 3) / 3 = 3

콘보이 효과(Convoy effect)가 발생
 * 큰 프로세스가 작업을 전부 처리할 동안 다른 프로세스들은 기다려야됨

nonpreemptive 방식이므로 타임 쉐어링(Time sharing) 환경에서는 부분적으로 문제가 발생한다.

### SJF(Shortest-Job-First) 스케쥴링

콘보이 효과를 방지하기 위해 만들어졌다.

<1> nonpreemptive 방식의 SJF

![sch_SJF](/images/sch_SJF.JPG "SJF")

burst time을 기준으로 제일 빠른것부터 채워넣는다.
*만약 burst time이 같을 경우, 먼저 도착한 것부터 넣는다.

`위 그림에서 Arrival Time을 생각하지 않은 프로세스의 Waiting time`

 * p1 = 3
 * p2 = 16
 * p3 = 9
 * p4 = 0

평균 Waiting time = (3 + 16 + 9 + 0) / 4 = 7


`위 그림에서 Arrival Time을 생각한 프로세스의 Waiting time`

 * p1이 먼저 도착하게 되므로 p1을 burst한다 (시간 6 경과)
 * p1이 burst되는 동안 p2, p3, p4가 전부 도착하므로(Arrival time이 각각 2, 4, 5) 이 중 burst time이 짧은 것부터 순서대로 큐에 넣는다.
 * (순서 = p1 - p4 - p3 - p2)

프로세스의 Waiting time

 * p1 = 0
 * p2 = 16
 * p3 = 9
 * p4 = 6

평균 Waiting time = (0 + 16(p4가 실행 시작된 시간)-2(p4의 arrival time) + 9(p3 이하동문) -4(p3 이하동문) + 6(p2 '')-5(p2 '')) / 4 = 5

**Arrival time은 프로세스가 로드가 끝난 시간을 의미한다.**

<2> preemptive 방식의 SJF

![sch_SJF2](/images/sch_SJF2.JPG "SJF")

 * p1이 먼저 도착한 뒤 1초동안 burst한다.
 * p2가 도착한 뒤에 p1의 남은 burst time보다 p2의 birst time이 작으므로 p1을 중지하고 p2를 burst한다.
 * 2초에 p3이 도착했지만 burst time은 p2가 여전히 p3보다 작아 p2 계속 진행
 * 3초에 p4가 도착했지만 burst time은 p2가 여전히 p4보다 작아 p2 계속 진행
 * 5초가 되면 p2는 4초의 모든 burst time이 끝나게 된다.
 * 각각 프로세스에 대해 남은 burst time은 p1 7초, p3 9초, p4 5초가 남게 되므로 p4를 실행한다.
 * p4 실행이 끝나고 다음으로 작은 burst time을 가진 p1이 실행된다.
 * 마지막으로 p3이 실행되고 프로그램이 종료된다.

프로세스의 Waiting time

 * p1 = 10(p1 마지막 실행 블록 시작점) -1(p1 그전의 burst time) - 0(p1 arrival time) = 9
 * p2 = 1(p2 마지막 실행 블록 시작점) -1(p2 arrival time) = 0
 * p3 = 17(p3 마지막 실행 블록 시작점) - 2(p3 arrival time) = 15
 * p4 = 5(p4 마지막 실행 블록 시작점) - 3(p4 arrival time) = 2

평균 Waiting time = (9 + 0 + 15 + 2) / 4 = 6.5

preemptive SJF 방식은 optimal (최적) - average waiting time이 최소이고, 프로세스 처리 시간이 평균을 유지한다.

실제 burst time의 계산은 유저가 정해준 값이나 과거의 히스토리로부터 exponential average를 통해 명령어 길이를 유추한다.

### Priority 스케쥴링

SJF 스케쥴링은 Priority 스케쥴링의 한 종류이다.

우선순위 internal 요소

 * 시간 제한
 * 요구 메모리
 * 불러오는 파일
 * 평균 I/O 버스트와 평균 CPU 버스트의 비율 (보통 I/O 버스트 비율이 높은 것의 우선순위가 더 높다)

![sch_priority](/images/sch_priority.JPG "priority")

우선순위(priority)에 따라 실행되며, 새 프로세스가 도착할 때마다 우선순위를 비교한다.

프로세스의 Waiting time

 * p1 = 6
 * p2 = 0
 * p3 = 16
 * p4 = 18
 * p5 = 1

평균 Waiting time = (6 + 0 + 16 + 18 + 1) / 5 = 8.2

starvation(=indefinite blocking) 문제(우선순위가 낮은 프로세스가 계속 실행되지 않는 문제)를 방지하기 위해 aging 도입

aging: 우선순위가 낮은 프로세스의 우선순위를 시간이 지남에 따라 높여주어 starvation 방지

### RR (Round-Robin) 스케쥴링

**Time quantum(time slice)이 도입되었다!**

![sch_RR](/images/sch_RR.JPG "Round Robin")

p1, p2, p3 순서로 실행되는데 각각 최대 Time Quantum 만큼의 시간만 할당받아서 최대 그 시간 만큼만 실행된다.

burst time이 time Quantum보다 작을경우는 burst time 내에서 처리한다.

![sch_RR_quantum1](/images/sch_RR_quantum.JPG "Round Robin")

이 모델에 대해서는 Context Switch와 Turnaround time이 주로 언급된다.

Context Switch는 프로세스를 swap하는 행위로, 많이 일어날수록 오버헤드가 커지게 된다.

![sch_RR_quantum2](/images/sch_RR_quantum2.JPG "Round Robin")

Turnaround time은 어떤 프로세스가 로드된 때로부터 실행이 완료될때까지 걸린 시간이다.ㅏ

time quantum(q)의 값이 1일 때 turnaround time은

 * p1 28
 * p2 29
 * p3 30
 
평균 turnaround time = (28 + 29 + 30) / 3 = 29

time quantum(q)의 값이 10일 때 turnaround time은

 * p1 10
 * p2 20
 * p3 30

평균 turnaround time = (10 + 20 + 30) / 3 = 20

time quantum 값을 너무 작게 설정할 경우 오버헤드가 커지고 처리시간이 오히려 느려진다. 80퍼센트의 프로세스의 cpu burst 타임이 타임 퀀텀보다 적어야 좋다.

### Multilevel Queue 스케쥴링

![sch_MQ](/images/sch_MQ.JPG "Multilevel Queue")

priority가 높은 큐부터 처리를 한다.

starvation 문제가 여전히 발생 가능하다.(아래쪽의 큐는 우선순위가 낮기 때문!)

큐마다 스케쥴링 구조가 다를 수 있다.

### Multilevel FeedBack Queue 스케쥴링

![sch_MFQ](/images/sch_MFQ.JPG "Multilevel FeedBack Queue")

위의 starvation 문제를 해결한 모델로 일정 시간마다 큐를 돌아가면서 실행한다.

큐마다 time quantum이 있으며 아래로 내려갈수록 time quantum이 커진다.

time quantum 안에 작업을 끝내지 못 할 경우 다음 큐로 넘어간다.

위쪽의 큐가 모두 끝났을 때도 끝나지 못한 매우 큰 프로세스는 맨 아래의 FCFS 큐로 빠져서 실행된다.

큐마다 스케쥴링 구조가 다를 수 있다.










# Exersize 문제들

# Inrto

1.1 다중프로그래밍과 시분할 환경에서, 다수의 사용자가 동시에 시스템을 공유한다. 이러한 상황은 여러 가지 보안 문제를 일으킬 수 있다

a. 그러한 문제점 두 가지는 무엇인가?

 1. 시스템 자원을 제어하기가 힘들다.

 2. 다른 사람이 내 데이터를 무단으로 접근, 변경할 수 있다.

b. 우리가 전용 컴퓨터에서 갖는 동일한 수준의 보안을 시분할 시스템에서도 보장할 수 있는가? 당신의 대답을 설명하시오.

 보장할 수 없다고 본다. 사람이 만든 보안시스템이라서 결함요소가 존재할 수 밖에 없다.


1.2 자원 활용의 문제는 운영체제의 유형별로 다른 모습으로 나타난다. 다음과 같은 환경에서는 어떤 자원들이 신중하게 관리되어야 하는지 나열하시오.

a. 메인 프레임 또는 미니컴퓨터 시스템 : 메인 프레임과 미니컴퓨터 시스템의 가장 큰 특징은 다소 성능을 포기하더라도 크기를 작게 만들고 휴대성을 높이는 것이다. 이러한 이유로 메인 프레임과 미니컴퓨터 시스템은 일반적인 컴퓨팅 시스템보다 CPU, 메모리, 저장 공간 등의 모든 자원이 더욱 신중하게 관리되어야 한다. 즉, 메인 프레임 또는 미니컴퓨터 시스템에 탑재되는 운영체제는 다른 시스템의 운영체제보다 모든 자원들에 대해 더욱 신중한 자원 관리를 필요로 한다.


b. 서버에 연결된 워크스테이션 : 서버 시스템에서 가장 중요한 자원은 CPU이다. 클라이언트에게 일정 시간 이내에 응답을 해야 한다는 점, 모든 클라이언트에게 동일한 자원을 사용할 수 있도록 해야 한다는 점은 모두 CPU 자원 관리와 연관된 문제이다.

또한, CPU의 성능이 중요한 서버 시스템에서는 보통 8코어, 16코어 등 많은 수의 CPU를 사용한다. 많은 수의 CPU를 관리하기 위해서 서버 시스템은 일반 PC 시스템보다 멀티 프로세싱 및 멀티 스레딩이 최적화된 옵션의 운영체제를 설치하기도 한다. 따라서, 서버에 연결된 워크스테이션에서는 개별 CPU에 대한 자원 관리와 각각의 CPU를 제어하기 위한 컨트롤 구조의 관리가 가장 중요하다.


c. 휴대용 컴퓨터 : 운영체제가 관리하는 영역을 다소 벗어난 감이 있지만, 휴대용 컴퓨터의 가장 중요한 자원은 전력 소모량이다. 휴대용 컴퓨터 시스템은 상대적으로 전력 소모량을 적게 소모하는 RISC (Reduced Instruction Sec Computer) 구조의 CPU를 이용한다. 또한 휴대용 컴퓨터는 시스템에 대용량 메모리를 구성하기 힘들기 때문에 메모리에 대한 자원 관리 또한 중요한 요소이다. 결국 휴대용 컴퓨터에서 가장 신중하게 관리되어야 하는 자원은 가장 전력 소모가 많은 CPU 및 입출력 자원과 메모리이다.


1.3 > 어떠한 상황에서 개인용 컴퓨터 또는 단일 사용자 워크스테이션을 사용하는 것보다 시분할 시스템을 사용하는 것이 더 좋은가?


-  주로 시분할 시스템은 많은 사람들에게 컴퓨터를 공유함으로서 빠른 시간 안에 사용자 전환이 가능하고 동작이나 명령이 짧은 예약시스템과 같은 상황에서 사용하는 것이 더 좋습니다.


1.4 대칭적 다중 처리와 비대칭 적 다중 처리의 차이점을 설명하시오. 다중 처리기 시스템의 세 가지 장점과 한 가지 단점은 무엇인가?


- 대칭적 다중 처리 방식의 다수의 CPU가 동급으로 연결되어 있고 비대칭적 다중 처리방식은 마스터 슬레이브 관계로 피 계층 CPU들과 그것들을 관리하는 CPU로 구성되어 있다. 비대칭적 다중 처리방식은 피 계층의 CPU들을 관리하는 CPU가 멈추면 프로그램이 멈추기 때문에 안전성이 떨어지는 반면 설계하기 쉽다. 대칭적 다중 처리 방식은 하나의 CPU가 멈춰도 다른 CPU가 멈춘 CPU의 일을 대신 할 수 있어서 안전성이 높지만 매번 다른 CPU의 동작 유무를 확인해야하기 때문에 오버헤드가 크다.


- 다중 처리기 시스템의 장점
    ➀처리기의 수가 늘어난 만큼 처리량도 증가(Increased of Throughput)

    ➁주변장치, 대용량 저장장치, 전원 공급 장치 공유(Economy of scale)

    ➂하나의 처리기가 동작을 멈춰도 다른 처리기가 그 일을 할 수 있음(Increased of Reliability)


- 다중 처리기 시스템의 단점

    단일 처리기 방식보다 OS가 처리해야 하는 것이 많고 OS 및 프로그램을 개발하기가 어렵다.


1.5 클러스터형 시스템과 다중 처리기 시스템의 차이점은 무엇인가? 고가용 서비스를 제공하기 위하여 한 클러스터에 속한 두 컴퓨터가 협력하는 데 필요한 것은 무엇인가?

 - 클러스터형 시스템은 여러 컴퓨터들을 단일 시스템으로 구성하여 작업을 클러스터에 분산하여 처리하고 다중처리기 시스템은 여러cpu들의 집합이고 공유메모리를 통해 통신한다.

- 두 컴퓨터가 서로를 감시해야한다.(한 프로세서가 실패하면 다른 프로세서가 실패한 프로세서를 대신할수 있어야 한다.)


1.6 하나의 데이터베이스를 수행하는 두 개의 노드로 구성된 컴퓨팅 클러스터를 고려해보자. 클러스터 소프트웨어가 디스크의 데이터에 대한 접근을 관리하는 두 가지 방법을 설명해 보시오. 각각의 장점과 단점을 논의하시오.


1) 접근 제어 : 접근 제어는 모든 기계에서 공유하는 소프트웨어 계층에서 하나의 기계만 데이터베이스에 접근하는 것을 허용하도록 데이터베이스를 관리하는 기법이다. 공유하는 소프트웨어 계층에서 모든 접근을 관리해야하고, 각 기계는 승인이 날 때까지 대기해야하기 때문에 자원 소모 및 성능 하락 등의 문제가 있지만 데이터베이스가 안정적인 것이 장점이다.


2) 잠금 기법 : 잠금 기법은 기계가 데이터베이스에 접근할 때, 데이터베이스가 사용 중이라는 것을 기계가 직접 명시하는 기법이다. 각 기계가 직접 데이터베이스에 대한 독점적인 접근을 관리하기 때문에 따로 관리 소프트웨어를 실행할 필요가 없다. 따라서 데이터베이스 성능이 접근 제어 방식보다 높고, 데이터베이스 시스템에서 따로 자원을 소모할 필요가 없다. 그러나 각 기계가 잘못된 실행으로 인해 데이터베이스에 대한 잠금을 하지 않으면, 데이터베이스 시스템의 안정성은 크게 하락하게 되는 단점이 있다.


1.7 > 네트워크 컴퓨터가 전통적 개인용 컴퓨터와 어떻게 다른가? 네트워크 컴퓨터를 사용하는 것이 유리한 사용 시나리오를 설명하시오.


- 전통적 개인용 컴퓨터는 네트워크 컴퓨터보다 원격 접근이나 이동성이 현저하게 낮습니다. 하지만 전통적 개인용 컴퓨터는 네트워크 컴퓨터보다 높은 보안이나 보수하는 것이 쉽습니다.


네트워크 컴퓨터를 이용하면 웹 기반으로 통해서 다양한 클라이언트들이  웹으로 통해서 원격 접근이 가능하고 어디서든 이용 가능한 이용성이 높다는 특징이 있습니다. 이를 이용해서 원거리의 회사 간의 메신저로 메시지를 주고받거나 회사 직원들이 회사 내부서버의 자료를 웹으로 쉽고 간단하게 이용하는데 네트워크 컴퓨터를 사용하는 것이 유리합니다.


1.8 인터럽트의 목적은 무엇인가? 트랩과 인터럽트의 차이점은 무엇인가? 트랩은 사용자 프로그램에 의해 의도적으로 발생할 수 있는가? 만일 그렇다면 그 목적은 무엇인가?


- 인터럽트는 I/O가 CPU에게 자기 자신의 상태를 알리기 위해 존재한다. CPU와 I/O는 각각의 프로세스로 동작하기 때문에 CPU는 I/O에 대한 상태를 알지 못한다. 예로 들어 I/O는 할당 받은 일을 끝냈을 때 이와 같은 상태를 CPU에게 알려야하고 알리는 방식으로 인터럽트를 사용한다. 


- 인터럽트는 외부(I/O)에서부터 신호를 받는다고 하면 트랩은 내부에서 신호를 받는다. CPU내부에서 명령어를 수행 중 해당 주소에 명령어가 없거나 명령어 자체가 잘못되었을 때 트랩이 발생한다.


- 발생할 수 있다. 대표적으로 코드의 오류를 찾기 위한 디버깅용으로 사용된다.


1.9 CPU의 실행 부하가 증가하는 것을 피하기 위하여 직접 메모리 액세스 방식이 고속입출력 장치에 사용된다.

 a. 전송을 조율하기 위하여 CPU는 어떻게 장치와 인터페이스 하는가?

  -cpu가  특별한 레지스터를 사용하여 DMA를 조작한다. 그 장치는 cpu에서 명령을 받아     서 수행한다

 b. CPU는 메모리 연산이 종료되었음을 어떻게 알 수 있는가?

  - 수행이 끝나면 cpu에게 종료를 알리는 인터럽트를 보낸다.

 c. DMA가 데이터를 전송하는 동안 CPU는 다른 프로그램을 실행할 수 있다. 이 프로세스는 사용자 프로그램의 실행을 방해하는가? 만일 그렇다면, 어떤 형태의 방해가 발생하는지 설명하시오

  - DMA 장치와 CPU가 동시에 메모리에 접근하므로 최고속도가 나오지 않는다.


1.10 일부 컴퓨터 시스템은 모드 연산을 하드웨어로 제공하지 않는다. 이러한 컴퓨터에 안전한 운영체제를 구축할 수 있는지를 고려해 보자, 그것의 가능, 불가능 모두에 대한 논거를 제시하시오.


모드 연산을 소프트웨어적으로 제공한다는 것은 운영체제에서 소프트웨어적으로 모드 연산을 수행할 수 있다는 것과 같다. 운영체제의 본질은 결국 하드웨어에서 동작하는 소프트웨어이기 때문에 사용자 프로세스가 모드 연산에 접근하는 것을 방지하지 않는 운영체제를 사용자가 직접 시스템에 설치하여 구동하면 해당 컴퓨터 시스템은 얼마든지 사용자 프로세스에 의해 모드 연산이 수행될 수 있다.

만약 컴퓨터 시스템에 특정 운영체제만 설치할 수 있다면, 사용자 프로세스가 모드 연산에 접근하는 것을 방지하는 운영체제만 설치할 수 있도록 설정하면 된다. 그러나 이것은 운영체제에서 구현할 수 있는 기능이 아니라, 하드웨어적으로나 바이오스에서만 구현이 가능하다. 따라서 모드 연산을 소프트웨어적으로 제공하는 컴퓨터 시스템은 안전하지 않다.


1.11 > 많은 SMP 시스템은 다른 수준의 캐시를 갖는다. 한 수준은 각 처리 코어에 로컬하고 다른 수준은 모든 처리 코어가 공유한다. 왜 캐싱 시스템을 이렇게 설계했는가?


- 어떠한 A의 데이터 값이 모든 코어에 동시에 접근하게 되면 한 캐시에 A의 값이 변경될 경우 A가 있는 모든 코어의 캐시에 반영되어야 하기 때문에 캐시의 일관성의 문제에 어긋나게 됩니다. 결국 캐시의 일관성을 지키기 위해 메모리에 있는 A이 변경되고 이에 따라 다른 CPU 역시 변경됩니다. 이때 메모리의 접근 시간이 오래 걸리기 때문에 CPU들이 공유하는 중간 캐시를 두어 캐시의 값을 변경하고 해당 변경에 대한 각 cpu내부의 캐시들이 반영하는 식으로 속도를 줄일 수 있습니다.


1.12 그림1.6에 보인 것과 비슷한 SMP 시스템을 고려해 보자. 메모리에 저장된 데이터가 각 로컬 캐시에서 다른 값을 가질 수 있는 지를 예를 들어 그림으로 보여라



 - 위 그림의 대칭적 다중처리 방식을 볼 때 CPU들이 각각 다른 프로그램이 실행되고 있다고 한다면 CPU내  캐시메모리는 메인 메모리에 Load되어 있는 각각의 해당 프로그램의 자주 사용하는 데이터들이 들어 있다.

  

1.13 아래와 같은 처리 환경에서 어느 경우 캐시 데이터의 일관성 문제가 발생하는지 예를 들어 설명하시오.

a. 단일 처리기 시스템

  -어떤 시간에 하나의 프로세스만 실행하는 환경은 문제가 없다. 멀티태스킹 환경에서는 여러 프로세스가 어떤 값에 접근하기를 원할 때 프로세스들이 가장 최근에 갱신된 값을 얻는 거것을 보장해줘야 문제가 일어나지 않는다.

b. 다중 처리기 시스템

  -다른 프로세서에서 접근 할 수 있으므로 복사본 중 하나의 값이 갱신 될 경우 , 그 복사본이 존재하는 모든 캐시에 즉각 반영되어야한다.

c. 분산 시스템

  - 동일한 파일의 여러 개의 복사본이 병렬로 접근되고 갱신될 수 있으므로 , 한 곳에서 갱신될 경우 가능한 빨리 모든 복사본이 갱신될 것을 보장해야한다.


1.14 한 프로그램이 다른 프로그램이 사용하는 메모리르 변경하는 것을 막기 위하여 사용되는 메모리 보호 기법을 설명하시오.


대표적인 메모리 보호 기법은 아래와 같다.

1) 세그먼트 방식 :　컴퓨터 메모리를 여러 개의 크기가 다른 작은 세그먼트 (조각)로 분할하여 각각의 프로세스에게 세그먼트를 할당하고, 다른 세그먼트에 대한 접근을 제한하는 방식으로 메모리를 보호하는 기법이다. 이 때, 메모리 상한 레지스터와 메모리 하한 레지스터를 이용하여 프로세스가 접근할 수 있는 메모리 주소를 제한한다.


2) 페이징 : 페이징 기법은 가상 메모리를 물리 메모리에 매핑하여 메모리 공간을 사용하는 기법을 말한다. 일반적으로 프로세스는 페이지 테이블에 접근할 수 없기 때문에, 프로세스는 자신에게 할당된 페이지만 사용할 수 있다. 이러한 특성은 프로세스가 자신에게 할당된 페이지에만 접근할 수 있도록 하기 때문에 메모리 보호 기능을 수행할 수 있도록 한다. 페이징을 이용한 메모리 보호 기법은 x86 아키텍처와 같은 페이지 기반의 많은 컴퓨터 아키텍쳐에서 채택하고 있는 방법이다.


3) 보호키 : 물리 메모리를 특정 크기를 분할하여 각각 보호키를 할당한다. 시스템 하드웨어는 각 프로세스에 할당된 보호키에 대한 정보를 갖고 있다. 프로세스의 메모리 접근 시, 시스템 하드웨어는 프로세스가 접근하려는 메모리의 보호키와 프로세스가 갖고 있는 보호키를 비교하여 만약 보호키가 다르면 메모리 접근을 거부한다.


1.15 >  LAN과 WAN 중에서 아래의 환경에 가장 적합한 네트워크 구성은 무엇인가?


a. 대학 캠퍼스의 학생회관

        - 근거리 통신에 이용되는 LAN이 적합합니다.


b. 전체 주에 퍼져있는 다수의 대학의 캠퍼스

        - 대학 캠퍼스 사이의 거리가 멀기 때문에 LAN보다는 WAN을 이용하는 것이 적합    합니다.


c. 하나의 동네(예로 하나의 동 단위)

        - 하나의 동단위인 동네에서는 근거리 통신인 LAN이 적합합니다.


1.16 휴대용 장치의 운영체제를 설계할 때의 고려 사항을 전통적 PC의 운영체제 설계와 비교하여 설명해 보시오.

 - 휴대용 장치는 일반적인 전통적 PC와 다르게 전원 공급이 한정적이다. 그렇기 때문에 휴대용 장치의 운영체제는 한정적인 자원인 에너지를 얼마나 효율적으로 사용할 것인지 고려해서 설계되어야한다.


1.17 클라이언트 서버 시스템에 비해 피어 간 시스템의 장점은 무엇인가?

각 피어가 서비스를 요청/제공 하느냐에 의해 서버와 클라이언트로 동작한다.

클라이언트 서버 시스템은 서버가 제공하는 것만 받을 수 있지만 피어 간 시스템은 각자 필요한 것을 요청, 제공 할 수 있다.


1.18 피어간 시스템에 적합한 분산 응용을 다수 설명해 보시오.

먼저, P2P (Peer-to-Peer)방식의 장점으로는 클라이언트가 서버 역할을 할 수 있기 때문에 네트워크에 속한 클라이언트들이 자유롭게 애플리케이션과 파일 등을 공유할 수 있다는 것이 있다. 또한, P2P 네트워크는 무한대의 동시접속자 수용량을 갖으며, 수신을 원하는 수신자에게만 데이터를 전송하여 네트워크의 자원 낭비를 최소화한다.


1) 누텔라 (Gnutella) : 중앙 집중식 서버를 두지 않고, P2P 파일 공유 네트워크를 구성하기 위한 분산 소프트웨어 프로젝트이다.


2) 비트코인 : 특정 개인이나 기업이 운영하는 전자 화폐가 아니라, P2P 방식으로 여러 이용자의 컴퓨터에 분산되어 있는 가상 화폐이다. P2P 방식의 네트워킹 방식을 이용하여 은행같은 중간 단계를 거치지 않고 개인과 개인이 직접 거래할 수 있다. 또한, 화폐는 각각의 peer에서 특정한 알고리즘에 의해 생성된다.


3) 아발란셰 (Avalanche) : 파일을 각각의 peer에 특정 크기의 블록만큼 할당하여 네트워크상에서 파일을 공유하는 시스템이다. network codeing이라는 네트워킹 기술을 이용하여 파일 공유의 효율성을 향상시킨 것이 가장 큰 특징이다.


4) 프라우드넷 : 대한민국의 넷텐션에서 개발한 온라인 게임용 네트워크 서버 엔진이다. 소규모 및 대규모 다중 사용자 온라인 게임을 위한 서버 및 네트워크 엔진이다. 분산 서버 기능을 제공하여 서버의 편의성보다는 성능, 안전성, 유연성에 초점을 맞추어 개발되었다. 현재 출시된 많은 모바일 게임에서 이용하고 있는 서버 소프트웨어이다.


5) 프리넷 (Freenet) : 전자 우편, 정보 서비스, 대화식 통신, 그리고 회의가 가능한 공공 BBS (Bulletin Board System)이다.


1.19 > 오픈소스 운영체제의 여러 장점과 여러 단점을 열거하시오. 각 측면을 장점 또는 단점이라고 생각할 수 있는 사람들의 유형도 포함시키시오.


- 오픈 소스 운영체제 의 장점은 무료로 다운로드가 가능하고 수정이 요긴하기 때문에 개발비용이 매우 낮아지게 됩니다. 그리고 오픈소스는 여러 개발자들로 인해서 수정되고 개발되었기 때문에 코드의 안정성이 높아지게 됩니다. 그리고 오픈소스 운영체제로 인해서 코드의 체계가 더 탄탄해지면서 기술의 개발 발전 속도 가 높아지게 됩니다.

오픈 소스 운영체제의 단점은 일반 컴퓨터 이용자들에게는 익숙하지 않다는 것입니다 그리고 영리 회사가 아니기 때문에 갑작스럽게 지원의 보장이 되지 않을 수도 있다는 것입니다.


- 오픈 소스 운영체제를 장점이라고 생각하는 사람들의 유형들은 오픈소스 운영체제를 이용해서 비용도 줄여주고 프로그래머들에게 디버깅에 쉽고 용이하고 코드를 더 탄탄하게 만들 수 있기 때문에 컴퓨터를 공부하는 학생들, 개인 개발자들 그리고 간단하게 구현하고자 할 때 오픈소스 운영체제를 이용하는 것이 장점이라고 생각할 것입니다.

오픈 소스 운영체제를 단점이라고 생각하는 사람은 오픈소스 운영체제 보단 돈을 주고 구입한 MS같은 운영체제가 더 쉽고 용이하기 때문에 일반적인 프로그래밍 개발자 보다는 GUI에 익숙한 일반 컴퓨터 이용자들에게는 오픈소스 운영체제가 단점으로 생각할 것입니다.


출처: https://twinw.tistory.com/114?category=543743 [흰고래의꿈]

## Operating system

2.1 운영체제가 제공하는 서비스와 기능은 크게 두 범주로 나눌 수 있다. 두 범주에 대해 간략히 설명하고 차이점을 논의하시오

운영체제에 의해 제공되는 서비스의 한 부류는 시스템에서 동시에 실행되는 다른 프로세스들 간의 보호를 강화하는 것이다. 프로세스들은 자신의 주소 스페이스와 관련된 메모리 위치에만 접근할 수 있다. 또한 프로세스들은 다른 사용자와 관련된 파일을 바꿀 수 없다. 프로세스는 운영체제의 중재 없이 장치들에 직접 접근할 수도 없다.

운영체제가 제공하는 서비스의 다른 부류는 근본적인 하드웨어를 통해서는 직접 제공되지 않는 새로운 기능성을 제공하는 것이다. 가상 메모리와 파일 시스템은 운영체제에 의해 제공되는 새로운 서비스의 두 가지 예이다.


2.2 운영체제에게 매개변수를 전달하는 보편적인 방법 3가지를 설명하시오.

a. 레지스터 : 가장 간단한 방법으로 값을 레지스터에 저장하여 매개변수를 전달하는 방식이다. 이 방법은 가장 간단하면서도 신속한 매개변수의 전달이 가능하지만 매개변수가 레지스터보다 많은 경우에는 이용이 불가능한 방법이다.


b. 블록 또는 테이블 : 매개변수를 메모리 내의 블록이나 테이블에 저장하고, 블록의 주소를 레지스터에 저장하는 방식으로 매개변수를 전달한다.


c. 스택 : 스택 구조를 이용하여 응용프로그램은 스택에 push 연산을 수행하여 매개변수를 저장하고, 운영체제는 pop 연산을 이용하여 매개변수를 읽는 구조이다.



출처: https://twinw.tistory.com/115 [흰고래의꿈]

2.4 파일 관리와 관련된 운영체제의 다섯 가지 주요 활동은 무엇인가?

    ➀ 사용자 프로세스와 시스템 프로세스의 생성과 제거

    ➁ 프로세스의 일시중지와 재 수행

    ➂ 프로세스 동기화를 위한 기법 제공

    ➃ 프로세스 통신을 위한 기법 제공
    ➄ 교착상태 처리를 위한 기법 제공


출처: https://twinw.tistory.com/115 [흰고래의꿈]

2.5 파일과 장치에 대한 접근을 처리하기 위해 같은 시스템 호출 인터페이스를 사용할 때의 장단점은 무엇인가?

(모놀리식구조)

 장점: 오버헤드가 거의 없다(시스템 호출에 의한 서비스가 빠르다)

 단점: 구현이 어렵고 유지보수가 어렵다


출처: https://twinw.tistory.com/115 [흰고래의꿈]

2.9 운영체제의 두 구성요소가 서로에게 종속적인 경우 계층구조로 시스템을 구성하는 것이 어려울 때가 있다. 서로의 기능이 밀접하게 연결되어 있어서 계층구조로 나누는 방법이 불분명한 경우를 제시하시오.

 입출력 연산 프로그램이 재귀적으로 돌아가는 경우 첫 번째 수행 결과값을 두 번째 입력값으로 반영하려는 경우 하위계층에서 상위계층의 값을 가져와야 하는데 계층구조라서 불가능 할 것이다

가상 메모리 하위 시스템과 저장소 하위 시스템은 전형적으로 단단히 연결되어 있고, 다음에 나오는 상호작용들 때문에 계층화된 시스템에서의 신중한 디자인을 요구한다. 많은 시스템은 파일이 실행중인 프로세스의 가상메모리 스페이스에 맵되는 것을 허락한다.

반면에 가상 메모리 하위 시스템은 현재 메모리에 위치하지 않은 backing store를 제공하기 위해 전형적으로 저장소 시스템을 사용한다. 또한, 파일시스템의 업데이트는

  

그것이 디스크에 플러쉬(flush)되기 전에 때때로 물리적 메모리에 버퍼된다. 그렇게 함으로써 가상 메모리 하위 시스템과 파일 시스템 간의 메모리 사용의 신중한 조직화를 요구한다.

  예비 저장 장치를 위한 장치드라이버는 메모리 관리가 예비저장장치를 사용할 수 있는 능력을 필요로 하기 때문에 메모리 관리 루틴들보다 하위층에 있어야한다.


2.10 시스템을 설계할 때 마이크로커널 방식을 사용하는 장점은 무엇인가? 마이크로커널 구조에서 사용자 프로그램과 시스템 서비스가 상호작용하는 방식에 대해 설명하시오, 마이크로커널 방식을 사용할 때의 단점은 무엇인가?

마이크로커널이란, 커널을 최대한 경량화한 커널 구조이다. 커널을 경량화함으로써, 마이크로커널은 확장성이 뛰어나고 새로운 시스템 구조에 이식하는 것이 쉽다는 장점이 있다. 이외에도 커널에서 수행하는 기능이 적으므로, 버그나 시스템 취약점이 현저하게 감소하여 커널이 더 안정적이고 안전하다는 장점이 있다.

마이크로커널에서 사용자 프로그램과 시스템 서비스는 주로 메시지 전달을 이용하여 상호작용한다. 예를 들어, 입출력 장치에 대한 사용자 프로그램과 시스템 서비스간의 메시지 전달 방식의 동작 구조를 보면 동작은 아래와 같이 진행된다.

1) 사용자 프로그램이 운영체제에게 메시지를 전달한다.

2) 마이크로운영체제는 자신이 입출력을 직접 처리하는 것이 아니라, 인터럽트를 처리하는 프로세스에게 사용자 프로그램의 메시지를 전달한다.

3) 인터럽트 처리기는 메시지를 스케줄링하여 순서나 우선순위에 따라 메시지를 처리한다.


이러한 마이크로커널에는 단점 또한 존재하는데, 마이크로커널의 가장 큰 단점은 커널과 통신하기 위해 발생하는 성능 오버헤드이다. 마이크로커널은 주로 이 문제를 해결하기 위해 발달하는 경향을 보였으며, Message Direct Transfer, Short Message 등 다양한 메시지 전달 방식이 연구되었다.


2.11 > 적재가능 커널 모듈을 사용하는 장점은 무엇인가?

- 커널을 자주 재구축 해줄 필요가 없습니다. 그리고 적재가능 커널 모듈을 유지하고 오류를 수정하는 것이 빠릅니다. 또한 필요할 시 모듈을 로드 할 수 있어서 코드를 커널에서 모듈로 이동하면 커널의 memory footprint 가 줄어듭니다. 디바이스 드라이버나 파일 시스템을 로드 가능한 커널 모듈로 구현시에 추가적으로 커널 구성이나 컴파일 필요 없이 커널에 로드가 가능합니다. 모듈에서 임의의 다른 모듈을 호출할 수 있다는 점 에서 계층보다 유연하다는 장점이 있습니다. 



출처: https://twinw.tistory.com/115 [흰고래의꿈]


2.14 실험적인 Synthesis 운영체제는 커널 안에 어셈블러가 포함되어 있다. 시스템 호출의 성능을 최적화하기 위해, 커널은 커널 공간 내의 루틴을 어셈블 하여 반드시 지나가야 할 커널 경로를 최소화한다. 이러한 접근 방법은 계층적 접근 방법과는 반대되는 것으로 계층적 접근 방법에서는 운영체제 구현을 쉽게 하기 위해 커널 경로를 연장한다. 커널 설계 측면과 시스템 성능 최적화 측면에서 Synthesis 방식의 장단점을 논의하시오.

a. 장점 : 어셈블러가 커널에 포함되어 있기 때문에 다른 운영체제에서는 어셈블러가 하나의 응용프로그램으로 간주되어 발생할 메시지 전달 상의 오버헤드가 Synthesis에서는 발생하지 않는다. 성능적 측면 외에도, 프로그래머가 시스템이나 커널에 맞는 어셈블러를 직접 설치해야하는 번거로움이 없다는 장점 또한 존재한다.


b. 단점 : 커널이 하나의 응용프로그램을 직접 동작시키는 것과 같기 때문에 커널의 복잡성이 증가한다. 기본적으로 커널을 외부에서 변경하는 것은 불가능하기 때문에, 프로그래머는 자신이 사용하고자하는 어셈블러를 이용할 수 없는 경우가 존재할 수 있으며, 컴파일러와 같이 어셈블러를 구현해야하는 응용프로그램들은 Synthesis에 맞는 프로그램을 따로 개발해야하는 번거로움이 존재한다. 이외에도 어셈블러를 업데이트하기 위해서는 커널 자체의 코드를 수정해야하기 때문에 유지 및 보수가 어려워지는 단점 또한 존재한다.


출처: https://twinw.tistory.com/115 [흰고래의꿈]



## thread

What are three differences between user-level threads and kernel-level threads?
(1) User-level threads are unknown by the kernel, whereas the kernel is aware of kernel threads.
(2) On systems using either M:1 orM:N mapping, user threads are scheduled by the thread library and the kernel schedules kernel threads. (3) Kernel threads need not be associated with a process whereas every user thread belongs to a process.

Under what circumstances does a multithreaded solution using multiple kernel threads provide better performance than a single-threaded solution on a single-processor system?
When a kernel thread suffers a page fault, another kernel thread can be switched in to use the interleaving time in a useful manner. A single-threaded process, on the other hand, will not be capable of performing useful work when a page fault takes place. Therefore, in scenarios where a program might suffer from frequent page faults or has to wait for other system events, a multithreaded solution would perform better even on a single-processor system.


concurrently와 simultaneously (parallelism)은 다르다.

The two processors were running concurrently, then they crashed simultaneously.


## process

• CPU utilization and response time: CPU utilization is increased if the overheads associated with context switching is minimized. The context switching overheads could be lowered by performing context switches infrequently. This could however result in increasing the response time for processes.

• Average turnaround time and maximum waiting time: Average turnaround time is minimized by executing the shortest tasks first. Such a scheduling policy could however starve long-running tasks and thereby increase their waiting time.

• I/O device utilization and CPU utilization: CPU utilization is maximized by running long-running CPU-bound tasks without performing context switches. I/O device utilization is maximized by scheduling I/O-bound jobs as soon as they become ready to run, thereby incurring the overheads of context switches.


The primary advantage of each processing core having its own run queue is that there is no contention over a single run queue when the scheduler is running concurrently on 2 or more processors. When a scheduling decision must be made for a processing core, the scheduler only need to look no further than its private run queue. A disadvantage of a single run queue is that it must be protected with locks to prevent a race condition and a processing core may be available to run a thread, yet it must first acquire the lock to retrieve the thread from the single queue. However, load balancing would likely not be an issue with a single run queue, whereas when each processing core has its own run queue, there must be some sort of load balancing between the different run queues.


4. Consider a system running ten 1/O-bounds tasks and one CPU-bound task. Assume that the I/O-bound tasks issue an I/O operation once for every millisecond of CPU computing and that each I/Ooperation takes 10 milliseconds to complete. Also assume that the context-switching overhead is 0.1millisecond and all processes are long-running tasks. What is the CPU utilization for a round-robinscheduler when: a) The time quantum is 1 millisecondb) The time quantum is 10 millisecondAnswer:(a) The time quantum is 1 millisecond: Irrespective of which process is scheduled, the scheduler incursa 0.1 millisecond context-switching cost for every context-switch. This results in a CPU utilization of1/1.1 * 100 = 91%.(b) The time quantum is 10 milliseconds: The I/O-bound tasks incur a context switch after using uponly 1 millisecond of the time quantum. The time required to cycle through all the processes istherefore 10*1.1 + 10.1 (as each I/O-bound task executes for 1 millisecond and then incur the contextswitch task, whereas the CPU-bound task executes for 10 milliseconds before incurring a contextswitch). The CPU utilization is therefore 20/21.1 * 100 = 94%.

3.11 다음에 나오는 기법들의 장점과 단점은 무엇인가? 시스템 관점과 프로그래머 관점을 모두 고려하시오.

a. 동기적 통신과 비동기적 통신: 동기적 통신은 메시지를 보내고 답변이 올 때까지 해당 답변을 기다리는 방식으로 시스템 관점과 프로그래머 관점에서 구현이 간단하다는 장점이 있지만, 답변이 올 때가지 프로세스가 어떠한 작업도 할 수 없다는 단점이 존재한다. 반대로 비동기적 통신은 이벤트 핸들러를 이용해야 하는 등의 오버헤드가 발생하지만, 통신을 하면서 프로세스가 다른 작업을 수행할 수 있다는 장점이 있다.



b. 자동과 명시적 버퍼링: 자동 버퍼링의 경우에는 운영체제가 판단하기에 버퍼링이 필요한 경우에 버퍼링을 수행하기 때문에 시스템 관점에서는 효율적인 자원 활용이 장점이고 프로그래머의 관점에서는 프로그램 구현이 단순해진다는 장점이 존재한다. 그러나 어떠한 경우에는 프로그래머가 명시적으로 정의한 버퍼링보다 효율이 안 좋을 수도 있다. 반대로 명시적 버퍼링의 경우에는 프로그래머가 명시적으로 버퍼링을 수행하도록 구현해야하는 단점이 존재하지만 튜닝을 잘 하면 자동 버퍼링보다 높은 성능 향상을 기대할 수 있다.



c. 복사에 의한 송신과 참조에 의한 송신: 복사에 의한 송신은 원본 데이터는 그대로 유지하기 때문에 데이터의 안정성을 확보할 수 있지만, 데이터의 복사 과정에서 오버헤드가 발생하는 단점이 존재한다. 참조에 의한 송신은 데이터의 복사 과정이 없기 때문에 오버헤드가 발생하지 않는 장점이 존재하지만, 다른 함수나 객체에서 의도하지않게 원본 데이터의 값을 변경하게되는 side effect가 발생할 수도 있다.



d. 고정 크기와 가변 크기 메시지: 고정 크기 메시지는 시스템 관점에서 항상 고정된 크기의 메시지를 다루기 때문에 파이프라이닝, 버퍼링 등 시스템의 효율을 향상시킬 수 있는 기법을 활용할 수 있다는 장점이 존재하며, 프로그래머의 관점에서는 구현이 쉽다는 장점이 있다. 그러나 고정 크기 메시지는 설정된 크기보다 작은 크기의 메시지는 공간 낭비를, 설정된 크기보다 큰 메시지는 전송이 불가능하다는 단점이 존재한다. 반대로 가변 크기 메시지는 시스템이 연산을 최적화할 수 없다는 단점과 구현이 복잡해지는 단점이 존재하지만 공간을 효율적으로 활용할 수 있고, 메모리의 범위 안에서 모든 크기의 메시지를 전송할 수 있다는 장점이 존재한다.



출처: https://twinw.tistory.com/116?category=543743 [흰고래의꿈]



## 스케쥴링


Consider a preemptive priority scheduling algorithm based on dynamically changing priorities. Larger priority numbers imply higher priority. When a process is waiting for the CPU (in the ready queue, but not running), its priority changes at a rate α. When it is running, its priority changes at a rate β. All processes are given a priority of 0 when they enter the ready queue. The parameters α and β can be set to give many different scheduling algorithms.
a.Since β is a rate and it is greater than that of α, processes that are running will continually
receive a much higher priority. At the same time, the priority of processes waiting to be run will increase, however, this increase will not be as fast as the process
running on the CPU. This will result in a first-come first-serve (FCFS) type of situation where when no process is running the one that has been waiting the longest will be ran, and its priority will continuously increase faster than the others until it stops.

b. New processes in this scheme will always be ran immediately, and older processes
will sit in the ready queue until the most recent process finishes. This is essentially
Last In First Out.
